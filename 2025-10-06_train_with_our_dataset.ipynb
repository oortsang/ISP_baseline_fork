{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed164b70-fb54-4fd4-936c-a0f2e2354121",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3224e2-b6f3-49c6-a2dd-b02427ddde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.5\"\n",
    "\n",
    "from clu import metric_writers\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "import orbax.checkpoint as ocp\n",
    "\n",
    "import h5py\n",
    "import natsort\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage import geometric_transform\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec49c61-82cd-4100-8c23-c15163b25784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pysteps configuration file found at: /share/data/willett-group/oortsang/miniconda/envs/jaxisp-v3/lib/python3.13/site-packages/pysteps/pystepsrc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ISP_baseline.src import models, trainers, utils\n",
    "from ISP_baseline.models import Uncompressed \n",
    "\n",
    "from swirl_dynamics import templates\n",
    "from swirl_dynamics.lib import metrics\n",
    "from pysteps.utils.spectral import rapsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa0efa9-4223-4100-95d0-cee9bef10851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For use with our MFISNet-style dataset\n",
    "import os\n",
    "from ISP_baseline.src.data_io import (\n",
    "    load_hdf5_to_dict,\n",
    "    load_cart_multifreq_dataset,\n",
    "    load_single_dir_slice,\n",
    "    load_multi_dir_slice,\n",
    "    get_multifreq_dset_dirs,\n",
    ")\n",
    "from ISP_baseline.src.datasets import (\n",
    "    convert_mfisnet_data_dict,\n",
    "    setup_tf_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802b2e78-5208-4d2c-8e36-fb333ab4a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid tf to use GPU memory\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2abdd75-21fc-41fb-9c42-f59498a696b6",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b885f2d4-dfbb-4189-8c87-7e49a3587b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlc_repo = os.path.join(\"/\", \"home-nfs\", \"oortsang\", \"rlc-repo\")\n",
    "dataset_dir = os.path.join(rlc_repo, \"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2d81e86-55b9-4e42-959c-92554087e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 4 # number of levels (even number)\n",
    "# s = 12 # leaf size for N_x = 192\n",
    "# s = 5 # leaf size\n",
    "# s = 6\n",
    "s = 6\n",
    "# r = 3 # rank -- not used??\n",
    "\n",
    "# Discretization of Omega (n_eta * n_eta).\n",
    "neta = (2**L)*s\n",
    "\n",
    "# Number of sources/detectors (n_sc).\n",
    "# Discretization of the domain of alpha in polar coordinates (n_theta * n_rho).\n",
    "# For simplicity, these values are set equal (n_sc = n_theta = n_rho), facilitating computation.\n",
    "nx = (2**L)*s\n",
    "\n",
    "# Standard deviation for the Gaussian blur.\n",
    "blur_sigma = 0.5\n",
    "\n",
    "# Batch size.\n",
    "batch_size = 16\n",
    "\n",
    "# Number of training datapoints.\n",
    "# NTRAIN = 21000\n",
    "# NTRAIN = 2000 # Reduced for debugging purposes\n",
    "NTRAIN = 100 # for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc310b0c-1ab8-47d4-977b-8f49c1a4be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kbar_str_list = [\"2.5\", \"5\", \"10\"]\n",
    "kbar_str_list = [\"2\", \"5\", \"10\"] # uuhhh I haven't prepared the 2.5 data\n",
    "nk = len(kbar_str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0efc367a-135f-443a-a83a-ea18202c2cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: x_vals(192,), q_cart(100, 192, 192), sample_completion(100,), d_rs(100, 3, 192, 192)\n"
     ]
    }
   ],
   "source": [
    "# get_dset_dirs = lambda dset, kbar_list: [\n",
    "#     os.path.join(dataset_dir, f\"{dset}_train_measurements_nu_{kbar}\")\n",
    "#     for kbar in kbar_list\n",
    "# ]\n",
    "# train_dirs = get_dset_dirs(\"train\", kbar_str_list)\n",
    "train_dirs = get_multifreq_dset_dirs(\n",
    "    \"train\",\n",
    "    kbar_str_list,\n",
    "    base_dir=dataset_dir,\n",
    "    dir_fmt=\"{0}_measurements_nu_{1}\"\n",
    ")\n",
    "\n",
    "train_mfisnet_dd = load_cart_multifreq_dataset(\n",
    "    train_dirs,\n",
    "    global_idx_start=0,\n",
    "    global_idx_end=NTRAIN,\n",
    ")\n",
    "print(f\"Loaded: {', '.join([f'{key}{val.shape}' for (key, val) in train_mfisnet_dd.items()])}\")\n",
    "train_wb_dd = convert_mfisnet_data_dict(train_mfisnet_dd, blur_sigma=blur_sigma)\n",
    "# eta     = train_wb_dd[\"eta\"]\n",
    "# scatter = train_wb_dd[\"scatter\"]\n",
    "\n",
    "# Try downsampling since the sparsepolartocartesian step is so slow :((\n",
    "train_eta     = train_wb_dd[\"eta\"][..., ::2, ::2]\n",
    "train_scatter = train_wb_dd[\"scatter\"][..., ::2, ::2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "852a9d28-a656-4155-babe-ae87c9a5a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd = load_multi_dir_slice(\n",
    "#     train_dirs,\n",
    "#     global_idx_start=0,\n",
    "#     global_idx_end=10,\n",
    "#     load_keys=[\"q_cart\", \"d_rs\"],\n",
    "#     sample_keys=[\"q_cart\", \"d_rs\"],\n",
    "#     freq_dep_keys=[\"d_rs\"],\n",
    "# )\n",
    "# dd = load_single_dir_slice(\n",
    "#     train_dirs[-1],\n",
    "#     global_idx_start=0,\n",
    "#     global_idx_end=10,\n",
    "#     load_keys=[\"q_cart\", \"d_rs\"],\n",
    "#     ignore_keys=[\"d_rs\"],\n",
    "#     sample_keys=[\"q_cart\", \"d_rs\"],\n",
    "# )\n",
    "# dd_shapes = [f\"{key}{val.shape}\" for (key, val) in dd.items()]\n",
    "# print(f\"dd shapes: {', '.join(dd_shapes)}\")\n",
    "# dd[\"q_cart\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0363485f-b93b-4d35-9928-1eee1e7a6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_hdf5_to_dict(\"/home-nfs/oortsang/rlc-repo/dataset/train_measurements_nu_2/measurements_0.h5\").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8844ed2-507d-4ade-88c5-e8973cde4833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9921b616-aa69-4513-8c79-5b1dd9ed09c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 96, 96), (100, 96, 96, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eta.shape, train_scatter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c01ca3-aec6-471a-84d0-6252928e3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_dloader = setup_tf_dataset(\n",
    "    train_eta,\n",
    "    train_scatter,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa1c82e-62c1-4fc8-9925-2cda81b1d1d9",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bf578e5-79e7-4719-939e-76bb60252a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_cnn_layers = 3\n",
    "N_cnn_channels = 6\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d44ab0-c9a6-4852-8547-18935d0f9235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BCOO(float32[2304, 2304], nse=67049),\n",
       " Array([[   0,    1,    2, ...,   45,   46,   47],\n",
       "        [  48,   49,   50, ...,   93,   94,   95],\n",
       "        [  96,   97,   98, ...,  141,  142,  143],\n",
       "        ...,\n",
       "        [2159, 2112, 2113, ..., 2156, 2157, 2158],\n",
       "        [2207, 2160, 2161, ..., 2204, 2205, 2206],\n",
       "        [2255, 2208, 2209, ..., 2252, 2253, 2254]], dtype=int32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utils.load_mats_from_fp(os.path.join(\"tmp\", \"cart_and_rot_mats\", f\"mats_neta{neta}_nx{nx}.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b253d55-9982-4f3e-8d7c-1ad095a1ddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 ms, sys: 5.01 ms, total: 7.27 ms\n",
      "Wall time: 6.97 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cart_mat, r_index = utils.load_or_create_mats(\n",
    "    neta,\n",
    "    nx,\n",
    "    mats_dir=os.path.join(\"tmp\", \"cart_and_rot_mats\"),\n",
    "    mats_format=\"mats_neta{0}_nx{1}.npz\",\n",
    "    save_if_created=True,\n",
    ")\n",
    "# cart_mat = utils.SparsePolarToCartesian(neta, nx)\n",
    "# r_index  = utils.rotationindex(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfeae054-f6f8-48f1-b9b6-b6cd1bd96145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.sparse\n",
    "# sp_cart_mat = scipy.sparse.coo_array(\n",
    "#     (cart_mat.data, cart_mat.indices.T),\n",
    "#     shape=cart_mat.shape,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bdbdb02-1def-4feb-bc00-3b22d43a26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jax.experimental.sparse.bcoo import BCOO\n",
    "\n",
    "# jsp_cart_mat = BCOO((cart_mat.data, cart_mat.indices), shape=cart_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56c49201-74e3-4b6e-8d94-6cc84ebd9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_module = Uncompressed.UncompressedModelFlexible(\n",
    "    nx = nx,\n",
    "    neta = neta,\n",
    "    cart_mat = cart_mat,\n",
    "    r_index = r_index,\n",
    "    # New parameters\n",
    "    nk=nk,\n",
    "    N_cnn_layers=N_cnn_layers,\n",
    "    N_cnn_channels=N_cnn_channels,\n",
    "    kernel_size=kernel_size,\n",
    ")\n",
    "\n",
    "# core_module = Uncompressed.UncompressedModel(\n",
    "#     nx = nx,\n",
    "#     neta = neta,\n",
    "#     cart_mat = cart_mat,\n",
    "#     r_index = r_index,\n",
    "#     # # Doesn't support these\n",
    "#     # nk=nk,\n",
    "#     # N_cnn_layers=N_cnn_layers,\n",
    "#     # N_cnn_channels=N_cnn_channels,\n",
    "#     # kernel_size=kernel_size,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bebee1c-19b6-4bd3-b5b6-e06606f106d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = models.DeterministicModel(\n",
    "    input_shape = train_scatter[0].shape,\n",
    "    core_module = core_module\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f137de2-648d-412f-89e7-f39d048ad8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 70138\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(888)\n",
    "params = Model.initialize(rng)\n",
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
    "print('Number of trainable parameters:', param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14a42193-62e2-409d-a820-cd33a7908704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scatter[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bac17a7-2a9d-4308-9c1f-f7cb357abe7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jax.experimental.sparse.bcoo.BCOO"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cart_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48356746-9108-405d-9465-8049869dce4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jaxlib.xla_extension.ArrayImpl"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0527d33e-3f98-44cb-a242-05dfbe50bf7f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d22872e4-f1f9-4878-92c8-f534a5ab6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "num_train_steps = NTRAIN * epochs // 16  #@param\n",
    "workdir = os.path.abspath('') + \"/tmp/Uncompressed10squares\"  #@param\n",
    "initial_lr = 1e-5 #@param\n",
    "peak_lr = 5e-3 #@pawram\n",
    "warmup_steps = num_train_steps // 20  #@param\n",
    "end_lr = 1e-8 #@param\n",
    "ckpt_interval = 2000  #@param\n",
    "max_ckpt_to_keep = 3  #@param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0866784c-26de-4783-be04-a6d0705aa9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainers.DeterministicTrainer(\n",
    "    model=Model, \n",
    "    rng=jax.random.PRNGKey(42), \n",
    "    optimizer=optax.adam(\n",
    "        learning_rate=optax.warmup_cosine_decay_schedule(\n",
    "            init_value=initial_lr,\n",
    "            peak_value=peak_lr,\n",
    "            warmup_steps=warmup_steps,\n",
    "            decay_steps=num_train_steps,\n",
    "            end_value=end_lr,\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a904f8c1-995e-46d4-b640-69e3907ce5a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`pred` (16, 48, 48) and `true` (16, 96, 96) must have the same shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m eval_dloader = train_dloader\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtemplates\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworkdir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_train_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_train_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_writer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_writers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_default_writer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mworkdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_aggregation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_dloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_every_steps\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_batches_per_eval\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemplates\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTqdmProgressBar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtotal_train_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_train_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_monitors\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[43meval_monitors\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_rrmse_mean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemplates\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrainStateCheckpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mocp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCheckpointManagerOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m                \u001b[49m\u001b[43msave_interval_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_to_keep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_ckpt_to_keep\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/data/willett-group/oortsang/miniconda/envs/jaxisp-v3/lib/python3.13/site-packages/swirl_dynamics/templates/train.py:95\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(train_dataloader, trainer, workdir, total_train_steps, metric_aggregation_steps, eval_dataloader, eval_every_steps, num_batches_per_eval, run_sanity_eval_batch, metric_writer, callbacks)\u001b[39m\n\u001b[32m     93\u001b[39m   eval_iter = \u001b[38;5;28miter\u001b[39m(eval_dataloader)\n\u001b[32m     94\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m run_sanity_eval_batch:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metric_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     98\u001b[39m   metric_writer = metric_writers.create_default_writer(\n\u001b[32m     99\u001b[39m       workdir, just_logging=jax.process_index() > \u001b[32m0\u001b[39m\n\u001b[32m    100\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/data/willett-group/oortsang/miniconda/envs/jaxisp-v3/lib/python3.13/site-packages/swirl_dynamics/templates/trainers.py:164\u001b[39m, in \u001b[36mBaseTrainer.eval\u001b[39m\u001b[34m(self, batch_iter, num_steps)\u001b[39m\n\u001b[32m    160\u001b[39m eval_rng, preproc_rng = \u001b[38;5;28mself\u001b[39m.get_eval_rng(num=\u001b[32m2\u001b[39m)\n\u001b[32m    161\u001b[39m batch = \u001b[38;5;28mself\u001b[39m.preprocess_eval_batch(\n\u001b[32m    162\u001b[39m     batch_data=\u001b[38;5;28mnext\u001b[39m(batch_iter), rng=preproc_rng\n\u001b[32m    163\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m metrics_update = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compiled_eval_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_rng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m metrics_update = \u001b[38;5;28mself\u001b[39m._maybe_unreplicate(metrics_update)\n\u001b[32m    168\u001b[39m eval_metrics = eval_metrics.merge(metrics_update)\n",
      "    \u001b[31m[... skipping hidden 14 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/data/willett-group/oortsang/miniconda/envs/jaxisp-v3/lib/python3.13/site-packages/swirl_dynamics/templates/trainers.py:393\u001b[39m, in \u001b[36mBasicTrainer.eval_step.<locals>._eval_step\u001b[39m\u001b[34m(train_state, batch, rng)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_eval_step\u001b[39m(\n\u001b[32m    390\u001b[39m     train_state: BasicTrainState, batch: BatchType, rng: Array\n\u001b[32m    391\u001b[39m ) -> Metrics:\n\u001b[32m    392\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Use model to compute the evaluation metrics.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m   eval_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m      \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrng\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m   \u001b[38;5;66;03m# `eval_metrics` must include keys required by `EvalMetrics` definition\u001b[39;00m\n\u001b[32m    397\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.EvalMetrics.single_from_model_output(**eval_metrics)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/data/willett-group/oortsang/ISP_baseline_fork/ISP_baseline/src/models.py:66\u001b[39m, in \u001b[36mDeterministicModel.eval_fn\u001b[39m\u001b[34m(self, variables, batch, rng)\u001b[39m\n\u001b[32m     58\u001b[39m y = core(x)\n\u001b[32m     59\u001b[39m rrmse = functools.partial(\n\u001b[32m     60\u001b[39m     metrics.mean_squared_error,\n\u001b[32m     61\u001b[39m     sum_axes=(-\u001b[32m1\u001b[39m, -\u001b[32m2\u001b[39m),\n\u001b[32m     62\u001b[39m     relative=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     63\u001b[39m     squared=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     64\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(rrmse=\u001b[43mrrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43meta\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/data/willett-group/oortsang/miniconda/envs/jaxisp-v3/lib/python3.13/site-packages/swirl_dynamics/lib/metrics/regression.py:54\u001b[39m, in \u001b[36mmean_squared_error\u001b[39m\u001b[34m(pred, true, sum_axes, mean_axes, relative, squared)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Computes the mean squared error (MSE).\u001b[39;00m\n\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m \u001b[33;03mThe squared errors are first summed over a specified set of axes and then\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m \u001b[33;03m  The computed MSE array.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred.shape != true.shape:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     55\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`pred` \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and `true` \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrue.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must have the same shape.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     56\u001b[39m   )\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mean_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     59\u001b[39m   mean_axes = \u001b[38;5;28mtuple\u001b[39m(sum_axes) + \u001b[38;5;28mtuple\u001b[39m(mean_axes)\n",
      "\u001b[31mValueError\u001b[39m: `pred` (16, 48, 48) and `true` (16, 96, 96) must have the same shape."
     ]
    }
   ],
   "source": [
    "eval_dloader = train_dloader\n",
    "templates.run_train(\n",
    "    train_dataloader=train_dloader,\n",
    "    trainer=trainer,\n",
    "    workdir=workdir,\n",
    "    total_train_steps=num_train_steps,\n",
    "    metric_writer=metric_writers.create_default_writer(\n",
    "        workdir, asynchronous=False\n",
    "    ),\n",
    "    metric_aggregation_steps=10,\n",
    "    eval_dataloader=eval_dloader,\n",
    "    eval_every_steps = 100,\n",
    "    num_batches_per_eval = 1,\n",
    "    callbacks=(\n",
    "        templates.TqdmProgressBar(\n",
    "            total_train_steps=num_train_steps,\n",
    "            train_monitors=(\"train_loss\",),\n",
    "            eval_monitors=(\"eval_rrmse_mean\",),\n",
    "        ),\n",
    "        templates.TrainStateCheckpoint(\n",
    "            base_dir=workdir,\n",
    "            options=ocp.CheckpointManagerOptions(\n",
    "                save_interval_steps=ckpt_interval, max_to_keep=max_ckpt_to_keep\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb202d0-07f8-462f-8a10-7cee8d30dca5",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be1aeb-2023-45d9-a9b0-c045968ba402",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_state = trainers.TrainState.restore_from_orbax_ckpt(\n",
    "    f\"{workdir}/checkpoints\", step=None\n",
    ")\n",
    "\n",
    "inference_fn = trainers.DeterministicTrainer.build_inference_fn(\n",
    "    trained_state, core_module\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7d13a-fba7-4556-ab56-24315fe0db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "NTEST = 100\n",
    "\n",
    "test_dirs = get_multifreq_dset_dirs(\n",
    "    \"test\",\n",
    "    kbar_str_list,\n",
    "    base_dir=dataset_dir,\n",
    "    dir_fmt=\"{0}_measurements_nu_{1}\"\n",
    ")\n",
    "\n",
    "test_mfisnet_dd = load_cart_multifreq_dataset(\n",
    "    test_dirs,\n",
    "    global_idx_start=0,\n",
    "    global_idx_end=NTEST,\n",
    ")\n",
    "print(f\"Loaded: {', '.join([f'{key}{val.shape}' for (key, val) in test_mfisnet_dd.items()])}\")\n",
    "test_wb_dd = convert_mfisnet_data_dict(test_mfisnet_dd, blur_sigma=blur_sigma)\n",
    "\n",
    "# Try downsampling since the sparsepolartocartesian step is so slow :((\n",
    "test_eta     = test_wb_dd[\"eta\"][..., ::2, ::2]\n",
    "test_scatter = test_wb_dd[\"scatter\"][..., ::2, ::2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0728c6-9803-4ee5-a349-f8807e78d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset, test_dloader = setup_tf_dataset(\n",
    "    test_eta,\n",
    "    test_scatter,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e3cfa-b713-4b2f-9bdd-d4565ab42e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_errors_rrmse = [] \n",
    "validation_errors_rapsd = [] \n",
    "pred_eta = np.zeros(test_eta.shape)\n",
    "\n",
    "rrmse = functools.partial(\n",
    "        metrics.mean_squared_error,\n",
    "        sum_axes=(-1, -2),\n",
    "        relative=True,\n",
    "        squared=False,\n",
    "    )\n",
    "\n",
    "b = 0\n",
    "for batch in test_dloader:\n",
    "    # pred = inference_fn(batch[0])\n",
    "    pred = inference_fn(batch[\"scatter\"])\n",
    "    pred_eta[b*test_batch:(b+1)*test_batch,:,:] = pred\n",
    "    b += 1\n",
    "    true = batch[1]\n",
    "    validation_errors_rrmse.append(rrmse(pred=pred, true=true))\n",
    "    for i in range(true.shape[0]):\n",
    "        validation_errors_rapsd.append(np.abs(np.log(rapsd(pred[i],fft_method=np.fft)/rapsd(true[i],fft_method=np.fft))))\n",
    "\n",
    "print('relative root-mean-square error = %.3f' % (np.mean(validation_errors_rrmse)*100), '%') \n",
    "print('mean energy log ratio = %.3f' % np.mean(validation_errors_rapsd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7008cb5-e3bd-4c74-82c7-7cdc21b49fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(test_dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb067c7-765d-453e-b605-e9bdc3f50417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_path = os.path.abspath('../..') + '/data/10hsquares_testdata'\n",
    "# test_data_path = os.path.join(\"data\", \"testdata\")\n",
    "\n",
    "# with h5py.File(f'{test_data_path}/eta.h5', 'r') as f:\n",
    "#     # Read eta data, apply Gaussian blur, and reshape\n",
    "#     eta_re = f[list(f.keys())[0]][:, :].reshape(-1, neta, neta)\n",
    "#     blur_fn = lambda x: gaussian_filter(x, sigma=blur_sigma)\n",
    "#     eta_test = np.stack([blur_fn(img.T) for img in eta_re]).astype('float32')\n",
    "    \n",
    "# # Loading and preprocessing scatter data (Lambda)\n",
    "# # with h5py.File(f'{test_data_path}/scatter_order_8.h5', 'r') as f:\n",
    "# with h5py.File(f'{test_data_path}/scatter.h5', 'r') as f:\n",
    "#     keys = natsort.natsorted(f.keys())\n",
    "\n",
    "#     # Process real part of scatter data\n",
    "#     tmp1 = f[keys[3]][:, :]\n",
    "#     tmp2 = f[keys[4]][:, :]\n",
    "#     tmp3 = f[keys[5]][:, :]\n",
    "#     scatter_re = np.stack((tmp1, tmp2, tmp3), axis=-1)\n",
    "\n",
    "#     # Process imaginary part of scatter data\n",
    "#     tmp1 = f[keys[0]][:, :]\n",
    "#     tmp2 = f[keys[1]][:, :]\n",
    "#     tmp3 = f[keys[2]][:, :]\n",
    "#     scatter_im = np.stack((tmp1, tmp2, tmp3), axis=-1)\n",
    "    \n",
    "#     # Combine real and imaginary parts\n",
    "#     scatter_test = np.stack((scatter_re, scatter_im), axis=1).astype('float32')\n",
    "    \n",
    "# # Clean up temporary variables to free memory\n",
    "# del scatter_re, scatter_im, tmp1, tmp2, tmp3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c916a4-790c-4dd5-b205-00d18555a72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eed1d5-22f7-4b2f-a289-ad382e384903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9a0d4-6781-4481-8d15-331f02b06641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxisp-v3",
   "language": "python",
   "name": "jaxisp-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
