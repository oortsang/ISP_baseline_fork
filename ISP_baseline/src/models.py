
from collections.abc import Callable, Mapping
import dataclasses
import functools
from typing import Any, ClassVar, Protocol

from clu import metrics as clu_metrics
import flax
import flax.linen as nn
import jax
import jax.numpy as jnp
from swirl_dynamics.templates import models
from swirl_dynamics.templates import trainers
from swirl_dynamics.templates import train_states
from swirl_dynamics.lib import metrics

from .more_metrics import l2_error

Array = jax.Array
CondDict = Mapping[str, Array]
Metrics = clu_metrics.Collection
ShapeDict = Mapping[str, Any]  # may be nested
PyTree = Any
VariableDict = trainers.VariableDict

@dataclasses.dataclass(frozen=True, kw_only=True)
class DeterministicModel(models.BaseModel):

  input_shape: tuple[int, ...]
  core_module: nn.Module

  def initialize(self, rng: Array):
    # TODO: Add a dtype object to ensure consistency of types.
    x = jnp.ones((1,) + self.input_shape)
    return self.core_module.init(rng, x)

  def loss_fn(
      self,
      params: models.PyTree,
      batch: models.BatchType,
      rng: Array,
      mutables: models.PyTree,
  ) -> models.LossAndAux:

    y = self.core_module.apply({'params': params}, batch["scatter"])

    loss = jnp.mean(jnp.square(y - batch["eta"]))
    metric = dict(loss=loss)
    return loss, (metric, mutables)

  def eval_fn(
      self,
      variables: models.PyTree,
      batch: models.BatchType,
      rng: Array,
  ) -> models.ArrayDict:

    x = batch['scatter']
    core = self.inference_fn(variables, self.core_module)
    y = core(x)
    rrmse = functools.partial(
        metrics.mean_squared_error,
        sum_axes=(-1, -2),
        relative=True,
        squared=False,
    )
    # (OOT, 2025-10-08 adding relative l2 error)
    rel_l2 = functools.partial(
        l2_error,
        l2_axes=(-1, -2),
        relative=True,
        squared=False,
    )
    true_eta = batch['eta']
    eval_dict = {
      'rrmse':  rrmse(pred=y,  true=true_eta),
      'rel_l2': rel_l2(pred=y, true=true_eta),
    }
    # return dict(rrmse=rrmse(pred=y, true=batch['eta']))
    return eval_dict

  @staticmethod
  def inference_fn(variables: models.PyTree, core_module: nn.Module):

    def _core(
        x: Array
    ) -> Array:
      return core_module.apply(
          variables, x
      )

    return _core
